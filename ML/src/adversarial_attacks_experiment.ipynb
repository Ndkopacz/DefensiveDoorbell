{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from yolo_threat import YoloThreat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, images, labels, epsilon):\n",
    "    images.requires_grad = True\n",
    "    outputs = model(images)\n",
    "    loss = F.binary_cross_entropy_with_logits(outputs.squeeze(-1), labels.float())\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    perturbed_images = images + epsilon * images.grad.sign()\n",
    "    return torch.clamp(perturbed_images, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels, epsilon=0.3, alpha=2 / 255, iters=40):\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.to(device)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    ori_images = images.clone().detach()\n",
    "\n",
    "    for i in range(iters):\n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs.squeeze(-1), labels.float())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        adv_images = images + alpha * images.grad.sign()\n",
    "        eta = torch.clamp(adv_images - ori_images, min=-epsilon, max=epsilon)\n",
    "        images = torch.clamp(ori_images + eta, min=0, max=1).detach_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_t, X, y):\n",
    "    model_t.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model_t.forward(X)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        y_pred = (y_pred > 0.5).float().reshape(-1)\n",
    "        accuracy = np.mean((y_pred.cpu() == y.cpu()).numpy())\n",
    "\n",
    "        # Calculate precision, recall, and F1 score\n",
    "        y_true = y.cpu().numpy()\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_robustness(model, X, y, epsilons, attack_fn, attack_name):\n",
    "    results = {}\n",
    "    for epsilon in epsilons:\n",
    "        print(f\"Evaluating {attack_name} attack with epsilon={epsilon:.3f}\")\n",
    "        if attack_name == \"Normal\":\n",
    "            perturbed_X = X  # No perturbation for normal evaluation\n",
    "        else:\n",
    "            perturbed_X = attack_fn(model, X, y, epsilon=epsilon)  # Updated parameter for PGD\n",
    "\n",
    "        acc, precision, recall, f1 = test(model, perturbed_X, y)\n",
    "        results[epsilon] = {\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1\n",
    "        }\n",
    "        print(\n",
    "            f\"Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\"\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(results_dict):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for attack_name, results in results_dict.items():\n",
    "        epsilons = list(results.keys())\n",
    "        accuracies = [metrics[\"accuracy\"] for metrics in results.values()]\n",
    "        plt.plot(epsilons, accuracies, marker='o', label=attack_name)\n",
    "\n",
    "    plt.xlabel(\"Epsilon\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Adversarial Robustness: Accuracy vs Epsilon\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = torch.load('../data/danger/raw/train.pt').to(device)\n",
    "ytrain = torch.load('../data/danger/raw/train_labels.pt').to(device)\n",
    "Xtest = torch.load('../data/danger/raw/test.pt').to(device)\n",
    "ytest = torch.load('../data/danger/raw/test_labels.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YoloThreat.load_new_model().to(device)\n",
    "model.load_state_dict(torch.load('trained_model.pt', map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, 0.05, 0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating normal model performance...\")\n",
    "# accuracy, precision, recall, f1 = test(model, Xtest, ytest)\n",
    "# normal_results = {0: {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1}}\n",
    "normal_results = evaluate_robustness(model, Xtest, ytest, [0], lambda m, x, y, epsilon: x, \"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm_results = evaluate_robustness(model, Xtest, ytest, epsilons, fgsm_attack, \"FGSM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd_results = evaluate_robustness(model, Xtest, ytest, epsilons, pgd_attack, \"PGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"Normal\": normal_results, \"FGSM\": fgsm_results, \"PGD\": pgd_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(results_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs580",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
