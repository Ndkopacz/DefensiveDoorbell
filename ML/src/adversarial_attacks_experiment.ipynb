{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo_threat import YoloThreat\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tune import Tuner\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from IPython.display import display, clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, images, labels, epsilon):\n",
    "    images.requires_grad = True\n",
    "    outputs = model.forward(images)\n",
    "    loss = torch.nn.BCEWithLogitsLoss()(outputs.squeeze(-1), labels.float())\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    perturbation = epsilon * images.grad.sign()\n",
    "    adv_images = torch.clamp(images + perturbation, 0, 1).detach()\n",
    "    return adv_images\n",
    "\n",
    "def pgd_attack(model, images, labels, epsilon, alpha, iters):\n",
    "    adv_images = images.clone().detach()\n",
    "    adv_images.requires_grad = True\n",
    "    for _ in range(iters):\n",
    "        outputs = model.forward(adv_images)\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(outputs.squeeze(-1), labels.float())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        adv_images = adv_images + alpha * adv_images.grad.sign()\n",
    "        perturbation = torch.clamp(adv_images - images, -epsilon, epsilon)\n",
    "        adv_images = torch.clamp(images + perturbation, 0, 1).detach_()\n",
    "        adv_images.requires_grad = True\n",
    "    return adv_images\n",
    "\n",
    "\n",
    "def add_gaussian_noise(images, noise_level=0.05):\n",
    "    noisy_images = images + noise_level * torch.randn_like(images)\n",
    "    return torch.clamp(noisy_images, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialTrainer:\n",
    "    def __init__(self, tuner, Xtrain, ytrain, epsilon=0.1, alpha=0.01, attack_iters=5, noise_level=0.05):\n",
    "        self.tuner = tuner\n",
    "        self.Xtrain = Xtrain\n",
    "        self.ytrain = ytrain\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.attack_iters = attack_iters\n",
    "        self.noise_level = noise_level\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def adversarial_training(self, batch_size=32):\n",
    "        train_dataset = TensorDataset(self.Xtrain, self.ytrain)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        adv_X, adv_y = [], []\n",
    "        self.tuner.model.train()  # Ensure the model is in training mode\n",
    "\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            print(f\"Generating adversarial examples for batch {batch_idx + 1}/{len(train_loader)}\")\n",
    "\n",
    "            X_batch, y_batch = X_batch.detach(), y_batch.detach()\n",
    "\n",
    "            # Clean examples\n",
    "            adv_X.append(X_batch)\n",
    "            adv_y.append(y_batch)\n",
    "\n",
    "            # FGSM examples\n",
    "            fgsm_X = fgsm_attack(self.tuner.model, X_batch, y_batch, self.epsilon)\n",
    "            adv_X.append(fgsm_X.detach())  # Detach after creating adversarial example\n",
    "            adv_y.append(y_batch)\n",
    "\n",
    "            # PGD examples\n",
    "            pgd_X = pgd_attack(self.tuner.model, X_batch, y_batch, self.epsilon, self.alpha, self.attack_iters)\n",
    "            adv_X.append(pgd_X.detach())\n",
    "            adv_y.append(y_batch)\n",
    "\n",
    "            # Gaussian Noise examples\n",
    "            noisy_X = add_gaussian_noise(X_batch, self.noise_level)\n",
    "            adv_X.append(noisy_X.detach())\n",
    "            adv_y.append(y_batch)\n",
    "\n",
    "        # Combine all adversarial examples\n",
    "        adv_X = torch.cat(adv_X)\n",
    "        adv_y = torch.cat(adv_y)\n",
    "        print(f\"Adversarial examples generated. Total examples: {adv_X.shape[0]}\")\n",
    "        return adv_X, adv_y\n",
    "\n",
    "    def fine_tune_with_adversarial(self, optimizer=optim.Adam, epochs=50, batch_size=32, lr=0.001, **kwargs):\n",
    "        # Generate adversarial examples\n",
    "        print(\"Starting adversarial example generation...\")\n",
    "        adv_X, adv_y = self.adversarial_training(batch_size=batch_size)\n",
    "\n",
    "        # Fine-tune the model with adversarial examples\n",
    "        print(\"Starting adversarial fine-tuning...\")\n",
    "        optimizer = optimizer(self.tuner.model.parameters(), lr=lr)\n",
    "\n",
    "        train_dataset = TensorDataset(adv_X, adv_y)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        criterion = self.tuner.get_loss(kwargs.get(\"lam\", 0.01))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "            self.tuner.model.train()\n",
    "\n",
    "            epoch_loss = 0\n",
    "            for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                X_batch, y_batch = X_batch.detach(), y_batch.detach()  # Detach to prevent graph accumulation\n",
    "                y_pred = self.tuner.model.forward(X_batch).squeeze(-1)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                print(f\"Batch {batch_idx + 1}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            self.train_losses.append(avg_epoch_loss)\n",
    "            print(f\"Epoch {epoch + 1} completed | Average Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "            # Generate validation loss\n",
    "            self.tuner.model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                val_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    y_pred = self.tuner.model.forward(X_batch).squeeze(-1)\n",
    "                    val_loss += criterion(y_pred, y_batch).item()\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            self.val_losses.append(avg_val_loss)\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "            # Dynamic Plotting\n",
    "            clear_output(wait=True)\n",
    "            self.plot_error_trace(dynamic=True)\n",
    "\n",
    "        print(\"Adversarial fine-tuning completed.\")\n",
    "        self.plot_error_trace(dynamic=False)\n",
    "        return self.tuner.model\n",
    "\n",
    "    def plot_error_trace(self, dynamic=False):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.train_losses, label=\"Training Loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        if dynamic:\n",
    "            display(plt.gcf())  # Display dynamically\n",
    "        else:\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model with Metrics\n",
    "def evaluate_model_with_metrics(model, X, y, epsilon, batch_size=32):\n",
    "    model.eval()\n",
    "    data_loader = DataLoader(TensorDataset(X, y), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_preds_clean = []\n",
    "    all_labels_clean = []\n",
    "    all_preds_adv = []\n",
    "    all_labels_adv = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            # Clean predictions\n",
    "            outputs = model.forward(X_batch)\n",
    "            preds_clean = torch.round(torch.sigmoid(outputs.squeeze(-1))).cpu().numpy()\n",
    "            all_preds_clean.extend(preds_clean)\n",
    "            all_labels_clean.extend(y_batch.cpu().numpy())\n",
    "\n",
    "            # Adversarial predictions (FGSM)\n",
    "            X_adv = fgsm_attack(model, X_batch, y_batch, epsilon)\n",
    "            outputs_adv = model.forward(X_adv)\n",
    "            preds_adv = torch.round(torch.sigmoid(outputs_adv.squeeze(-1))).cpu().numpy()\n",
    "            all_preds_adv.extend(preds_adv)\n",
    "            all_labels_adv.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # Convert predictions and labels to NumPy arrays\n",
    "    all_preds_clean = np.array(all_preds_clean)\n",
    "    all_labels_clean = np.array(all_labels_clean)\n",
    "    all_preds_adv = np.array(all_preds_adv)\n",
    "    all_labels_adv = np.array(all_labels_adv)\n",
    "\n",
    "    # Compute metrics for clean predictions\n",
    "    clean_precision = precision_score(all_labels_clean, all_preds_clean)\n",
    "    clean_recall = recall_score(all_labels_clean, all_preds_clean)\n",
    "    clean_f1 = f1_score(all_labels_clean, all_preds_clean)\n",
    "    clean_acc = np.mean(all_preds_clean == all_labels_clean) * 100\n",
    "\n",
    "    # Compute metrics for adversarial predictions\n",
    "    adv_precision = precision_score(all_labels_adv, all_preds_adv)\n",
    "    adv_recall = recall_score(all_labels_adv, all_preds_adv)\n",
    "    adv_f1 = f1_score(all_labels_adv, all_preds_adv)\n",
    "    adv_acc = np.mean(all_preds_adv == all_labels_adv) * 100\n",
    "\n",
    "    print(\"Clean Data Metrics:\")\n",
    "    print(f\"Accuracy: {clean_acc:.2f}%, Precision: {clean_precision:.2f}, Recall: {clean_recall:.2f}, F1 Score: {clean_f1:.2f}\")\n",
    "    print(\"Adversarial Data Metrics (FGSM):\")\n",
    "    print(f\"Accuracy: {adv_acc:.2f}%, Precision: {adv_precision:.2f}, Recall: {adv_recall:.2f}, F1 Score: {adv_f1:.2f}\")\n",
    "\n",
    "    return {\n",
    "        \"clean\": {\n",
    "            \"accuracy\": clean_acc,\n",
    "            \"precision\": clean_precision,\n",
    "            \"recall\": clean_recall,\n",
    "            \"f1_score\": clean_f1\n",
    "        },\n",
    "        \"adversarial\": {\n",
    "            \"accuracy\": adv_acc,\n",
    "            \"precision\": adv_precision,\n",
    "            \"recall\": adv_recall,\n",
    "            \"f1_score\": adv_f1\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/harshitsingh/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2024-11-22 Python-3.12.2 torch-2.2.2 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n6 summary: 280 layers, 3239884 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = YoloThreat.load_new_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8736, 3, 128, 128]),\n",
       " torch.Size([8736]),\n",
       " torch.Size([2185, 3, 128, 128]),\n",
       " torch.Size([2185]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = torch.load('../data/danger/raw/train.pt')\n",
    "ytrain = torch.load('../data/danger/raw/train_labels.pt')\n",
    "Xtest = torch.load('../data/danger/raw/test.pt')\n",
    "ytest = torch.load('../data/danger/raw/test_labels.pt')\n",
    "Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape: torch.Size([8736, 3, 128, 128]), ytrain shape: torch.Size([8736])\n",
      "Xtest shape: torch.Size([2185, 3, 128, 128]), ytest shape: torch.Size([2185])\n"
     ]
    }
   ],
   "source": [
    "# Xtrain = torch.nn.functional.interpolate(Xtrain, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "# Xtest = torch.nn.functional.interpolate(Xtest, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "\n",
    "# print(f\"Xtrain shape: {Xtrain.shape}, ytrain shape: {ytrain.shape}\")\n",
    "# print(f\"Xtest shape: {Xtest.shape}, ytest shape: {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting adversarial example generation...\n",
      "Generating adversarial examples for batch 1/18\n"
     ]
    }
   ],
   "source": [
    "tuner = Tuner(model, data_dir=(Xtrain, ytrain))\n",
    "# Initialize AdversarialTrainer\n",
    "adversarial_trainer = AdversarialTrainer(\n",
    "    tuner=tuner,\n",
    "    Xtrain=Xtrain,\n",
    "    ytrain=ytrain,\n",
    "    epsilon=0.1,\n",
    "    alpha=0.01,\n",
    "    attack_iters=3,\n",
    "    noise_level=0.02\n",
    ")\n",
    "\n",
    "tuned_model = adversarial_trainer.fine_tune_with_adversarial(\n",
    "    optimizer=optim.Adam,\n",
    "    epochs=1,\n",
    "    batch_size=512,\n",
    "    lr=1,\n",
    "    freeze_limit=20,\n",
    "    warmup=0.1,\n",
    "    lam=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuned_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m evaluate_model_with_metrics(\u001b[43mtuned_model\u001b[49m, Xtest, ytest, epsilon)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuned_model' is not defined"
     ]
    }
   ],
   "source": [
    "epsilon = 0.1\n",
    "evaluate_model_with_metrics(tuned_model, Xtest, ytest, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs580",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
